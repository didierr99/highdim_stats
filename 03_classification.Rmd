# Extension to Classification and Survival Analysis

```{r include=FALSE}
library(knitr)
library(caret)
library(mlbench)
library(glmnet)
library(tidyverse)
library(e1071)
library(MASS)
library(party)
library(pec)
library(tidyverse)
library(glmnet)
```

We so far focused on the linear regression model. We will now extend to the setting where the response is binary or time-to-event. The former is often referred to as classification and the latter as survival analysis.

## Classification

We focus on the binary situation where response $G$ takes values $0$ and $1$, and, the aim is to do prediction based based on covariates $X=(X_1,\ldots,X_p)$. We model the probability of success $$p(x;\beta)=P(G=1|X=x;\beta)$$ using the logistic regression approach with logit link function

\[\rm{logit}(x;\beta)=log \Big(\frac{p(x;\beta)}{1-p(x;\beta)}\Big)=X^T\beta.\]

In logistic regression we estimate the regression parameter $\beta$ by maximizing the log-likelihood

\begin{align*}
\ell(\beta|\bf G,\bf X)&=\sum_{i=1}^{n}(1-g_i)\log(1-p(x_i;\beta))+g_i\log p(x_i;\beta)\\
&=\sum_{i=1}^{n}g_i x_i^T\beta - \log(1+\exp(x_i^T\beta)).
\end{align*}

Given an estimate $\hat \beta$ (from training data), prediction based on new input data $X_{\rm new}$ can be obtained via the predicted probablity of success $p(X_{\rm new};\hat \beta)$, e.g. the class labels corresponding to the maximum probability

\begin{align*}
  \hat{G}(X_{\rm new})=\left\{
    \begin{array}{ll}
      1, & \mbox{if $p(X_{\rm new};\hat\beta)>0.5$}.\\
      0, & \mbox{otherwise}.
    \end{array}
  \right.
\end{align*}

Similar as in linear regression, in the high-dimensional context where $n$ is small compared to $p$, the maximum likelihood estimator does often lead to overfitting and a poor generalisation error. We will in the following generalize the previously introduced idea of regularization to classification. In the context of linear regression we penalized the residual sum of squares (RSS). We extend this and penalize the negative log-likelihood with an elastic net penalty

\begin{align*}
\hat{\beta}_{\alpha,\lambda}&=\rm{argmin}-\frac{1}{n}\ell(\beta|{\bf G},{\bf X})+\lambda\big((1-\alpha)\|\beta\|_2^2/2+\alpha\|\beta\|_1\big).
\end{align*}

With $\alpha=1$ we obtain the Lasso penalty and with $\alpha=0$ the Ridge penalty.

There are different measures to judge the quality of the predictions. We focus on the missclassification error which is simply the fraction of missclassified test samples. Another important measure used in the context of classification is the receiver operating characteristic (ROC). 

### South African Heart Disease Data

We start with a "low" dimensional example illustrating the logistic regression model and comparing 
the Lasso with traditional backward selection. The data shown in Figure \@ref(fig:sahd) are a
subset of the Coronary Risk-Factor Study (CORIS) baseline survey, carried
out in three rural areas of the Western Cape, South Africa (Rousseauw et al, 1983, South African Medical
Journal). The aim of the study was to establish the intensity of ischemic
heart disease risk factors in that high-incidence region. The data represent
white males between 15 and 64, and the response variable is the presence or
absence of myocardial infarction (MI) at the time of the survey (the overall
prevalence of MI was 5.1% in this region). There are 160 cases in our data
set, and a sample of 302 controls. This example is taken from the book @elements. The variables are:

- sbp: systolic blood pressure
- tobacco: cumulative tobacco (kg)
- ldl: low densiity lipoprotein cholesterol adiposity
- famhist: family history of heart disease (Present, Absent)
- obesity
- alcohol: current alcohol consumption
- age: age at onset
- chd: response, coronary heart disease.

```{r sahd,echo=FALSE, fig.cap="South African Heart Disease Data",fig.height=10,fig.width=10}
# data source: https://web.stanford.edu/~hastie/ElemStatLearn/
dat <-  read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",sep=",",head=T,row.names=1)
vars <- c("chd","sbp","tobacco","ldl","famhist","obesity","alcohol","age")
dat <- dat[,vars]

pairs(data.matrix(dat[,-1]),col=ifelse(dat$chd==1,"red","blue"))
```

We first fit a logitstic-regression model. 

```{r}
fit.logistic <- glm(chd~sbp+tobacco+ldl+famhist+obesity+alcohol+age,data=dat,family="binomial")
kable(broom::tidy(fit.logistic),digits=3)
```


There are some surprises in this table of coefficients, which must be interpreted with caution. Systolic blood pressure (sbp) is not significant! Nor
is obesity, and its sign is negative. This confusion is a result of the correlation between the set of predictors. On their own, both sbp and obesity
are significant, and with positive sign. However, in the presence of many other correlated variables, they are no longer needed (and can even get a
negative sign).

We proceed with backward selection.

```{r, echo=FALSE}
fit.bw <- stepAIC(fit.logistic,direction = "backward",trace=FALSE)
```

```{r}
kable(as.data.frame(fit.bw$anova),digits=3)
```

The regression coefficients of the selected model are

```{r}
kable(broom::tidy(fit.bw),digits=3)
```

How does one interpret a coefficient of $0.081$ (Std. Error = $0.026$) for
tobacco, for example? Tobacco is measured in total lifetime usage in kilograms, with a median of $1.0$kg for the controls and $4.1$kg for the cases. Thus
an increase of 1kg in lifetime tobacco usage accounts for an increase in the
odds of coronary heart disease of $\exp(0.081) = 1.084$ or $8.4$%. Incorporating the standard error we get an approximate $95$% confidence interval of
$\exp(0.081 ± 2 × 0.026) = (1.03, 1.14)$.

Finally we run the Lasso approach

```{r}
x <- scale(data.matrix(dat[,-1]))
y <- dat$chd
fit.lasso <- glmnet(x=x,y=y,family="binomial")
plot(fit.lasso,xvar = "lambda",label=TRUE)
```

The first coefficient which is shrunk to zero is alcohol followed by obesity and sbp. This is in line with the results from backward selection.

We now turn to a truly high-dimensional example.

### Leukemia Dataset

<!--  Example from https://cran.r-project.org/web/packages/varbvs/vignettes/leukemia.html -->

The data consists of expression levels recorded for $3'571$ genes in $72$ patients with leukemia (Golub et al, 1999). The binary outcome encodes the disease subtype: acute lymphobastic leukemia (ALL) or acute myeloid leukemia (AML). The data are represented as a 72 x 3,571 matrix $\bf X$ of gene expression values, and a vector $\bf y$ of 72 binary disease outcomes. We first create train and test data.

```{r}
# set seed
set.seed(15)

# get leukemia data
library(varbvs) # varbvs package contains the diabetes data
data(leukemia)
x <- leukemia$x
y <- leukemia$y

# test/train 
ind_train <- sample(1:length(y),size=length(y)/2)
xtrain <- x[ind_train,]
ytrain <- y[ind_train]
xtest <- x[-ind_train,]
ytest <- y[-ind_train]
```

We now run the elastic net

```{r}
# set settings for glmnet 
nfolds <- 10                  # number of cross-validation folds.
alpha  <- 0.95                # elastic net mixing parameter.

# run glmnet
fit.glmnet <-glmnet(xtrain,ytrain,family = "binomial",alpha=alpha)

```

The following Figure shows the trace plot of Elastic net.

```{r}
plot(fit.glmnet,xvar="lambda",label=TRUE)
```

We run 10-fold cross-validation and show the missclassification error. 

```{r}
# run cv.glmnet
cv.glmnet <- cv.glmnet(xtrain,ytrain,family = "binomial",type.measure = "class",
                       alpha = alpha,nfolds = nfolds)
plot(cv.glmnet)
```

We take $\lambda_{\rm opt}$ as the largest $\lambda$ within 1 standard error of the minimum classification error

```{r}
(lambda.opt <- cv.glmnet$lambda.1se)
```

and extract the optimal coefficients and plot them as a barplot.

```{r}
beta.glmnet <- coef(fit.glmnet, s = cv.glmnet$lambda.1se)
barplot(as.numeric(beta.glmnet)[-1],xlab="gene",ylab="beta glment")
```

Finally we predict the disease outcome of the test samples using the fitted model and compare against the observed outcomes of the test samples.
```{r}
pred <- c(predict(fit.glmnet,xtest,s = lambda.opt,type = "class"))
print(table(true = factor(ytest),pred = factor(pred)))
```
The missclassification error on the test data is

```{r}
round(mean(pred!=ytest),3)
```

## Survival analysis

We turn our attention to survival analysis which deals with so-called time-to-event endpoints. We start with a very brief introduction to survival analysis and introduce the cox proportional hazards model. Then we turn to the high-dimensional setting and discuss elastic net regularization for cox regression. Finally, we introduce the time-dependent Brier score to compare prediction performance in the survival setting. 

### Survival analysis and proportional hazard model

For subject $i$ we denote the event time with $T_i$. Typically we do not for each subject observe the event time as a subject may be censored due to:

* Loss to follow-up
* Withdrawal from study
* No event by end of fixed study period.

Therefore in practise we observe the survival time $\widetilde{T}_i$ (which equals the event time or the censoring time whichever occurs earlier) and the event indicator $\delta_i$ ($\delta_i=1$ in case of event $=0$ in case of censoring).

A fundamental quantity in survival analysis is the survival probability

\[S(t)=P(T>t)=1-F(t).\]

The Kaplan-Meier method is the most common way to estimate survival times and probabilities in the context of censoring. 


Another important quantitiy is the hazard function $h(t)$, or the instantaneous rate at which events occur, which is defined as

\[h(t)=\lim_{dt\rightarrow 0}\frac{P(t\leq T < t+dt|T\geq t)}{dt}=-S'(t)/S(t).\]

The Cox proportional hazards model is commonly used for the study of the relationship between predictor variables and survival time. The Cox model assumes a semi-parametric form for the hazard

\[h(t|X)=h_0(t)\exp(X^T\beta).\]

$h_0(t)$ is the baseline hazard and $\beta$ are the regression coefficients. In the classic cox regression estimation is done by optimizing the log partial likelihood $\ell(\beta|{\bf \widetilde{T} ,\Delta,X})$.

To learn more about survival analysis I recommend to have a look at this short tutorial https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html.


### Regularized Cox Regression

In a high-dimension setting classical cox-regression falls short. Similar as in the previous sections we can use subset selection or use regularization. The latter is implemented in the R package `glmnet` which penalizes the negative log of the partial likelihood with an elastic net penalty.


For illustration we consider the Lymphoma dataset which consists of gene expression data for $p=7399$ genes measured on $n=240$ patients, as well as censored survival times, for these patients. We start by reading the data.

```{r, include=FALSE}
# data source: http://web.stanford.edu/~hastie/StatLearnSparsity/data.html
# load packages for survival analysis
library(survival)
library(survminer)
set.seed(1)
```

```{r}
# read data
x <- read.table("data/lymphx.txt")%>%# gene expression matrix (covariates)
  as.matrix
topvar.genes <- order(apply(x,2,var),decreasing=TRUE)[1:500]
x <- scale(x[,topvar.genes])
y <- read.table("data/lymphtime.txt",header = TRUE)%>%# survival time and event variable
  as.matrix
dat <- data.frame(cbind(y,x))
```


Next we plot the estimated survival curve.
```{r}
# kaplan meier estimate
fit.surv <- survfit(Surv(time, status) ~ 1, data = dat)
ggsurvplot(fit.surv)
```

We can use the `summary` function to obtain more specific information on estimated survival quantities, e.g. the probability of surviving beyond 10 years is obtain as

```{r, eval=FALSE}
summary(survfit(Surv(time, status) ~ 1, data = dat), times = 10)
```

We are interested to find the genes which are most predictive for survival. We assume proportionality of hazards and use glmnet to perform L1-penalized cox regression. (Note that we only consider $p=500$ genes with largest variance.)

```{r}
set.seed(1)
fit.coxnet <- glmnet(x, y, family = "cox",alpha=0.95)
plot(fit.coxnet,xvar="lambda")
```

To identify the optimal lambda we use cross-validation and take Harrel's concordance index as a goodness of fit measure. 

```{r}
cv.coxnet <- cv.glmnet(x,y,
                       family="cox",
                       type.measure="C",
                       alpha=0.95)
plot(cv.coxnet)
```

The C-index ranges from 0.5 to 1. A value of 0.5 means that the model is no better than predicting an outcome than random chance. The tuning parameter which maximizes the C-index is $lambda_{\rm{opt}}=$ `r round(cv.coxnet$lambda.min,2)`. The next graphic shows the magnitude of the non-zero coefficients (note that we standardized the input covariates).

```{r, echo=FALSE}
dbeta <- data.frame(NULL)
dbeta <- data.frame(betahat=as.numeric(coef(fit.coxnet,s=cv.coxnet$lambda.min)))
dbeta$betaname <- colnames(x)
dbeta%>%
  dplyr::filter(betahat!=0)%>%
  ggplot(.,aes(x=reorder(betaname,abs(betahat)),y=abs(betahat)))+
  geom_bar(stat="identity",width=0.25)+
  xlab("gene")+ylab("abs(betahat)")+
  theme(axis.text.x = element_text(angle = 45, hjust =1,size=7),
        text = element_text(size = 15))
```

### Brier score and predictions in survival analysis

Evaluating the predictive performance of survival models is an important topic. A popular score to measure the prediction accuracy is the time-dependent Brier score

\[{\rm BS}(t,\hat{S})={\bf E}(Y_{\rm{new}}(t)-\hat{S}(t|X_{\rm new})) \]

where $Y_{\rm{new}}(t)={\bf 1}(T_{\rm new}\geq t)$ is the true status of a new test subject and
$\hat{S}(t|X_{\rm new})$ is the predicted survival probability. Calculation of the Brier score is not trivial as we typically do not always observe the event time $T$ due to censoring. The R package `pec` estimates the Brier score using a technique called Inverse Probability of Censoring Weighting (IPCW). 

We split the data set into train and test data.

```{r}
train_ind <- sample(1:nrow(x),size=nrow(x)/2)
xtrain <- x[train_ind,]
ytrain <- y[train_ind,]
xtest <- x[-train_ind,]
ytest <- y[-train_ind,]
dtrain <- data.frame(cbind(ytrain,xtrain))
dtest <- data.frame(cbind(ytest,xtest))
```

For illustration we use forward selection on the training data to obtain a prediction model.

```{r}
fit.lo <- coxph(Surv(time,status)~1,data=dtrain,
              x=TRUE,y=TRUE)
up <- as.formula(paste("~", 
                       paste(colnames(xtrain), 
                             collapse="+")))
fit.fw <- stepAIC(fit.lo,
                  scope=list(lower=fit.lo,
                             upper=up),
                  direction="forward",
                  steps=5,
                  trace=FALSE)

```

The following table summarizes the variables added in each step of the forward selection approach.
```{r}
kable(as.data.frame(fit.fw$anova),digits=3)
```

The next figure shows a forest plot with estimated hazard ratios and confidence intervals. 

```{r, warning=FALSE}
survminer::ggforest(fit.fw)
```

Finally we use the `pec` package to calculate the Brier score on the training and test data.

```{r message=FALSE}
library(pec)
fit.pec.train <- pec::pec(
  object=list("cox.fw"=fit.fw), 
  data = dtrain, 
  formula = Surv(time, status) ~ 1, 
  splitMethod = "none")


fit.pec.test <- pec::pec(
  object=list("cox.fw"=fit.fw), 
  data = dtest, 
  formula = Surv(time, status) ~ 1, 
  splitMethod = "none")

```
The following figure shows the Brier scores evaluated on train and test data.
```{r}
par(mfrow=c(1,2))
plot(fit.pec.train,main="train")
plot(fit.pec.test,main="test")
```

The plot on the right indicates that the selected model performs no better than the reference model (no covariates).

The `pec` package can also be used to benchmark different prediction models. We illustrate this based on random survival forest and backward selection. In this illustration we do not split the data into training and test. Instead we use cross-validation to compare the two prediction approaches.

We focus on only the covariates which have non-zero coefficient in the previous glmnet fit.

```{r}
shat <- dbeta%>%
  dplyr::filter(betahat!=0)%>%
  pull(betaname)
fm <- as.formula(paste0("Surv(time, status) ~ ",paste(shat,collapse = "+")))
```


We start by fitting random forest using the `party` package.

```{r}
fit.cforest <- pec::pecCforest(fm, data =dat, 
                              control = party::cforest_classical(ntree = 100))
```

We can obtain a measure of variable importance using the function `varimp`.

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.height=8}
vp <- party::varimp(fit.cforest$forest)
dvp <- data.frame(VARNAME=names(vp),VARIMP=vp)
vplot <- dvp%>%
  arrange(desc(VARIMP))%>%
  ggplot()+
  geom_point(aes(x = reorder(VARNAME, VARIMP), y = VARIMP), size = 3, shape = 18)+
  labs(title = "Variable Importance Random Survival Forest")+
  xlab("Variable")+
  ylab("Variable importance")+
  coord_flip()
print(vplot)
```

Next we run the Backward selection approach.

```{r}
fit.coxbw <- pec::selectCox(fm, data = dat, rule = "aic")
```

Finally we compare the prediction performance of the two approaches using the cross-validated Brier score. 

```{r message=FALSE}
pec.cv <- pec::pec(
  object=list("cox.bw"=fit.coxbw,"cforest"=fit.cforest), 
  data = dat, 
  formula = Surv(time, status) ~ 1, 
  splitMethod = "cv10")
plot(pec.cv)
```

Random forest exhibits a lower cross-validated Brier score.
