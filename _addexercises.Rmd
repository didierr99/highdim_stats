# Additional exercises

```{r, include=FALSE, warning=FALSE}
library(knitr)
library(glmnet)
library(tidyverse)
```

## Overfitting example

We illustrate overfitting based on simulated training and test data.

```{r message=FALSE}
set.seed(1)
n <- 20
p <- 50
# simulate covariates
xtrain <- matrix(rnorm(n*p),n,p)
xtest <- matrix(rnorm(n*p),n,p)
# simulate outcome
beta0 <- 0
beta <- c(2,0,0,0,2,rep(0,p-5))
ytrain <- beta0+xtrain%*%beta+rnorm(n,sd=0.5)
ytest <- beta0+xtest%*%beta+rnorm(n,sd=0.5)
# train and test data as data.frames
dtrain <- data.frame(cbind(ytrain,xtrain))
colnames(dtrain) <- c("y",paste0("x",1:ncol(xtrain)))
dtest <- data.frame(cbind(ytest,xtest))
colnames(dtest) <- c("y",paste0("x",1:ncol(xtrain)))
```

Linear regression with only x1.

```{r}
fit <- lm(y~x1,data=dtrain)
t.gp1 <- dtrain%>%
  ggplot(.,aes(x=x1))+
  geom_point(aes(y=y))+
  geom_line(aes(y=predict(fit)))
t.gp2 <- dtest%>%
  ggplot(aes(x=x1,y=y))+
  geom_point()+
  geom_line(aes(x=x1,y=predict(fit,newdata = dtest)),col="red")
grid.arrange(t.gp1,t.gp2,ncol=2)
```

Linear regression with 10 covariates.
```{r}
fm <- as.formula(paste0("y~",paste0("x",1:10,collapse="+")))
fit <- lm(fm,data=dtrain)
t.gp1 <- dtrain%>%
  ggplot(.,aes(x=x1))+
  geom_point(aes(y=y))+
  geom_line(aes(y=predict(fit)))
t.gp2 <- dtest%>%
  ggplot(aes(x=x1,y=y))+
  geom_point()+
  geom_line(aes(x=x1,y=predict(fit,newdata = dtest)),col="red")
grid.arrange(t.gp1,t.gp2,ncol=2)
```

Linear regression with 19 covariates
```{r}
fm <- as.formula(paste0("y~",paste0("x",1:19,collapse="+")))
fit <- lm(fm,data=dtrain)
t.gp1 <- dtrain%>%
  ggplot(.,aes(x=x1))+
  geom_point(aes(y=y))+
  geom_line(aes(y=predict(fit)))
t.gp2 <- dtest%>%
  ggplot(aes(x=x1,y=y))+
  geom_point()+
  geom_line(aes(x=x1,y=predict(fit,newdata = dtest)),col="red")
grid.arrange(t.gp1,t.gp2,ncol=2)
```

We perform Leap Forward Regression.


```{r warning=FALSE}
tc <- trainControl(method = "cv", number = 10)
fit.forward <- train(y ~., data = dtrain,
                     method = "leapForward", 
                     tuneGrid=data.frame(nvmax=1:15),
                     trControl = tc,
                     trace = FALSE
)
# nvmax
fit.forward$bestTune

# accuracy
fit.forward$results

# summary of the model
summary(fit.forward$finalModel)

# final model coefficients
coef(fit.forward$finalModel,2)%>%head
```


We perform Ridge regession

```{r}
lambda.max <- 10
lambda.min <- 10^{-6}*lambda.max
lambda.grid <- 10^seq(log10(lambda.min),log10(lambda.max),length=100)
fit.ridge<-train(y ~., 
                 data = dtrain,
                 method = "glmnet",
                 tuneGrid = expand.grid(alpha = 0,lambda=lambda.grid),
                 trControl = tc
) 

# CV plot
plot(fit.ridge)
# Best lambda
fit.ridge$bestTune$lambda
# Model coefficients
coef(fit.ridge$finalModel,fit.ridge$bestTune$lambda)%>%head
# Make predictions
fit.ridge %>% predict(dtest)%>%head
```

We perform Lasso regression.
```{r}
lambda.max <- max(abs(t(xtrain)%*%ytrain))/nrow(xtrain)
lambda.min <- 10^{-6}*lambda.max
lambda.grid <- 10^seq(log10(lambda.min),log10(lambda.max),length=100)
fit.lasso<-train(y ~., 
                 data = dtrain,
                 method = "glmnet",
                 tuneGrid = expand.grid(alpha = 1,lambda=lambda.grid),
                 trControl = tc
) 

# CV plot
plot(fit.lasso)
# Best lambda
fit.lasso$bestTune$lambda
# Model coefficients
coef(fit.lasso$finalModel,fit.lasso$bestTune$lambda)%>%head
# Make predictions
fit.lasso %>% predict(dtest)%>%head
```

Comparison between the 3 approaches
```{r}
models <- list(forward= fit.forward,ridge = fit.ridge,lasso=fit.lasso)
resamples(models) %>% 
  summary( metric = "RMSE")
```

That is how lambda_max is calculated.
```{r}
# with scaling
mysd <- function(y) sqrt(sum((y-mean(y))^2)/length(y))
sx <- scale(xtrain,scale=apply(xtrain, 2, mysd))
sx <- as.matrix(sx, ncol=20, nrow=100)
sy <- as.vector(scale(ytrain, scale=mysd(ytrain)))
max(abs(colSums(sx*sy)))/nrow(xtrain)
fitglmnet <- glmnet(sx,sy)
max(fitglmnet$lambda)

# no scaling
fit.lasso <-glmnet(x=xtrain,y=ytrain,
                   alpha=1,
                   standardize=FALSE,
                   intercept=FALSE) 
max(fit.lasso$lambda)
max(abs(t(xtrain)%*%ytrain))/nrow(xtrain)
```



```{r, eval=FALSE, include=FALSE}
set.seed(1)
spam <- readRDS(file="data/spam.rds")
colnames(spam)[58] <- "spam"
spam$spam <- factor(spam$spam)
# b) Fit a random Forest (library(randomForest)) with the default settings. 

library(randomForest)
set.seed(123)
system.time(rf.spam <- randomForest(spam ~ ., data = spam)) # about 17 sec
plot(rf.spam)



# c) Plot the error rate vs. the number of fitted trees. How many trees are necessary? Refit the model with the chosen number of trees. How long does it take now?

plot(rf.spam)# Choose no more than 100 trees.
set.seed(123)
system.time(rf.spam <- randomForest(spam ~ ., data = spam, ntree = 100)) # about 3 sec
rf.spam

set.seed(123)
idx <- sample(1:nrow(spam), 2601)
dTrain <- spam[idx,]
dTest <- spam[-idx,]
rf.train <- randomForest(spam ~ ., data = dTrain, ntree = 100)
rf.train ## OOB error: 5.04%
pred.rf <- predict(rf.train, newdata = dTest)
mean(pred.rf != dTest$spam) ## Test error: 5.4%

```

Adaboost.
```{r}
dTrain$spam <- as.numeric(as.character(dTrain$spam))
fit.boost <-gbm(spam~.,data=dTrain,distribution = "adaboost") 
pred.boost <- ifelse(predict(fit.boost, newdata = dTest,type="response")>0.5,1,0)
predict(fit.boost,
        newdata=dTest[1:5,],
        type="response" )
mean(pred.boost != dTest$spam) ## Test error: 5.4%
```

```{r}
# load packages
library(rpart)
library(rpart.plot)

# grow a classification tree
fit.tree <- rpart(spam~.,data=dTrain,method="class")
rpart.plot(fit.tree,extra=1,under=TRUE,tweak = 1.2,faclen=3)
plotcp(fit.tree,cex.lab=1.5,cex.axis=1.2,cex=1.5)

fit.prune<- prune(fit.tree, 
                  cp=fit.tree$cptable[which.min(fit.tree$cptable[,"xerror"]),"CP"])
rpart.plot(fit.prune,extra=1)
mean(dTest$spam!=predict(fit.prune,newdata=dTest,type="class"))
```

