# High-dimensional feature assessment

```{r include=FALSE}
library(Biobase)
library(tidyverse)
```

A frequent task is to find features which differ with respect to one or more experimental factors. 
We illustrate this type of analysis using a gene expression expression experiment performed with $12$ randomly selected mice from two strains. The features are the $p=15923$ genes and the strain (A vs B) is the experimental factor.

A commonly used format for gene expression data is `ExpressionSet` class. The actual expressions are retrieved using the function `exprs`. Information on the phenotypes is obtained using `pData` and with `fData` we get more information on the genes ("features").

```{r, eval=FALSE, echo=FALSE}
# create subset of maPooling with only biological replicates
library(Biobase)
library(maPooling)
data(maPooling) ##this loads the three tables
pd <- pData(maPooling)
individuals <- which(rowSums(pd)==1)
individuals <- individuals[-grep("tr",names(individuals))] #rm technical replicates
g <- factor(as.numeric(grepl("b",names(individuals))))
levels(g) <- c("A","B")
maPooling_sub <- maPooling[,individuals]
maPooling_sub$strain <- g
save(maPooling_sub,file="data/maPooling_sub.rda")
```

We load the `ExpressionSet`.
```{r}
load("data/maPooling_sub.rda")
class(maPooling_sub)
dim(maPooling_sub)
```

We can look at the expression values for the first 6 genes.
```{r echo=FALSE}
head(exprs(maPooling_sub))
```
An overview on the phenotype and feature data can be obtained using the following commands.
```{r}
head(pData(maPooling_sub))
```

## Gene-wise two-sample comparison

We are interested in comparing gene expression between the 
mice strains A and B.

```{r}
x <- maPooling_sub$strain # strain information
y <- t(exprs(maPooling_sub)) # gene expressions matrix (columns refer to genes)
```

```{r include=FALSE}
n <- nrow(y)
p <- ncol(y)
```

We start by visualizing the expression of gene $j=11425$.

```{r}
boxplot(y[,11425]~x)
```

This gene seems to be higher expressed in A. To nail down this observeration we can do a more formal hypothesis test. We build the z-statistic

\begin{align*}
Z_{j}&=\frac{\bar{Y}_{j}^B-\bar{Y}_{j}^A}{S_{j}}.
\end{align*}

Approximately,  $Z_j\sim N(0,1)$ and we can calculate the two-sided p-value

\begin{align*}
P_j&=2(1-\Phi(Z_j)).
\end{align*}


In R we can perform a two-sample t-test using the function `t.test`. 

```{r}
ttest <- t.test(y[,11425]~x,var.equal=TRUE)
ttest$statistic #zscore
ttest$p.value
```

We obtain $P_{11425}=$`r round(ttest$p.value,3)` and based on that we would not reject the null-hypothesis for this specific gene at the $\alpha=5%$ level. What about the other genes? We continue by repeating the analysis for all $p=$ `r ncol(y)` genes. We save the results in a data frame.

```{r}
pvals <- apply(y,2,FUN=
                 function(y){
                   t.test(y~x,var.equal=TRUE)$p.value
                 })
zscore <- apply(y,2,FUN=
                  function(y){
                    t.test(y~x,var.equal=TRUE)$statistic
                  })
res.de <- data.frame(p.value=pvals,z.score=zscore,geneid=names(zscore))
```

Next we count the number of significant genes.

```{r}
sum(res.de$p.value<0.05)
```

According to this analysis `r sum(res.de$p.value<0.05)` genes are differentially expressed between strains A and B. This is `r round(100*sum(res.de$p.value<0.05)/p,1)`% of all genes. In the next section we will explain that this analysis misses an important point, namely it neglects the issue of multiple testing.

## Multiple testing

To illustrate the multiple testing problem we create an artificial gene expression data set where we are certain that none of the genes is differentially expressed.  

```{r}
set.seed(1)
p <- ncol(y)
n <- nrow(y)
ysim <- matrix(rnorm(n*p),n,p)
```

Now we repeat the gene-wise two-sample comparisons for the artificial data set.

```{r}
pvals.sim <- apply(ysim,2,FUN=
                 function(y){
                   t.test(y~x,var.equal=TRUE)$p.value
                 })
zscore.sim <- apply(ysim,2,FUN=
                  function(y){
                    t.test(y~x,var.equal=TRUE)$statistic
                  })
res.de.sim <- data.frame(p.value=pvals.sim,z.score=zscore.sim)
```

We count the number of significant genes.

```{r}
sum(res.de.sim$p.value<0.05)
```
This is a surprise! According to the analysis `r sum(res.de.sim$p.value<0.05)` genes are differentially expressed. However, we know that this cannot be true. What did we miss? The reason for the large number of falsely declared significant genes is that we performed multiple significance tests simultaneously. Each test is associated with an error which accumulate over the various test. In particular, we re-call that he probability of falsely rejecting the null-hypothesis (=Type-I error) is
\[
{\rm Prob}(P_j<\alpha)\leq \alpha. 
\]

We performed a significant test for each gene which makes the expected number of falsely rejected null-hypotheses $p\times\alpha$=`r p*0.05`. Under the null hypothesis we would expect the p-values to follow a uniform distribution. Indeed, that is what we observe in our simulation example.

```{r}
hist(res.de.sim$p.value)
```

The distribution of p-values obtained from the real example has a peak near zero which indicates that some genes are truly differentially expressed between strains A and B.

```{r}
hist(res.de$p.value)
```

In the next section we will discuss *p-value adjustment* which is a method to counteract the issue of multiple testing.


## P-value adjustment

Our previous consideration suggest that we could adjust the p-values by multiplying with the number $p$ of performed tests, i.e.

\[P_{j}^{\rm adjust}=p\times P_j.\]

This adjustment method is known as the Bonferroni correction. The method has the property that it controls the so-called family-wide-error rate (FWER). The derivation goes as follows

\begin{align*}
{\rm FWER}&={\rm Prob}({\rm at\;least\;one\;rejection})\\
&={\rm Prob}({\rm min}\; P^{\rm adjust}_j\leq \alpha)\\
&={\rm Prob}({\rm min}\; P_j\leq \alpha/p)\\
&\leq \sum_{j=1}^p {\rm Prob}(P_j\leq \alpha/p)\\
&=p\frac{\alpha}{p}=\alpha.
\end{align*}

In our example we calculate the Bonferroni adjusted p-values.

```{r}
res.de$p.value.bf <- p*res.de$p.value
res.de.sim$p.value.bf <- p*res.de.sim$p.value
```

The number of significant genes in the real and simulated dataare provided next. In particular none of the genes is significant in the simulated data which is in line with our expectations.

```{r}
sum(res.de$p.value.bf<0.05)
sum(res.de.sim$p.value.bf<0.05)
```


The R function `p.adjust` offers various adjustment procedures. The different methods are based on different assumption and/or control a different error measure. The Bonferroni correction is the most conservative approach and often leads to too few significant result (loss of statistical power). Less conservative is the so-called FDR approach which controls the False Discovery Rate (instead of FWER). We calculate the FDR adjusted p-values and print the number of significant genes.

```{r}
res.de$p.value.fdr <- p.adjust(res.de$p.value,method="fdr")
res.de.sim$p.value.fdr <- p.adjust(res.de.sim$p.value,method="fdr")
sum(res.de$p.value.fdr<0.05)
sum(res.de.sim$p.value.fdr<0.05)
```


## The Volcano plot

It is important to effectively display statistical results obtained from high-dimensional data. We have discussed how to calculate p-values and how to adjust them for multiplicity. However, the p-value is often not the only quantity of interest. In our example we are also interested to understand the effect size, that is the magnitude of the difference in expression between strains A and B. The following code calculates the effect sizes.

```{r}
ef<- apply(y,2,FUN=
             function(y){
               mba <- tapply(y,x,mean)
               return(mba[2]-mba[1])
             })
ef.sim <- apply(ysim,2,FUN=
                  function(y){
                    mba <- tapply(y,x,mean)
                    return(mba[2]-mba[1])
                  })
res.de$effectsize <- ef
res.de.sim$effectsize <- ef.sim
```

A frequently used display is the volcano plot which shows on the y-axis the $-\log_{10}$ p-values and on the x-axis the effect size. By using $-\log_{10}$, the “highly significant” features appear at the top of the plot. Using log also permits us to better distinguish between small and very small p-values. We can further highlight the "top genes" as those with adjusted p-value <0.05 and absolute effect size $>1$.

```{r}
res.de%>%
  dplyr::mutate(topgene=ifelse(p.value.fdr<0.05&abs(effectsize)>1,"top","other"))%>%
  ggplot(.,aes(x=effectsize,y=-log10(p.value),col=topgene))+
  geom_point()+
  scale_color_manual(values = c("top" = "red", "other" = "black"))+
  theme_bw()+
  theme(legend.position = "none")+
  xlim(-3,3)+ylim(0,10)+
  geom_vline(xintercept = 1)+
  geom_vline(xintercept = -1)
```

We repeat the same plot with the simulated data.

```{r}
res.de.sim%>%
  dplyr::mutate(topgene=ifelse(p.value.fdr<0.05&abs(effectsize)>1,"top","other"))%>%
  ggplot(.,aes(x=effectsize,y=-log10(p.value),col=topgene))+
  geom_point()+
  scale_color_manual(values = c("top" = "red", "other" = "black"))+
  theme_bw()+
  theme(legend.position = "none")+
  xlim(-3,3)+ylim(0,10)+
  geom_vline(xintercept = 1)+
  geom_vline(xintercept = -1)
```


## Variance shrinkage and empirical Bayes

The basis of the statistical analyses are the Z-scores 

\begin{align*}
Z_{j}&=\frac{\bar{Y}_{j}^B-\bar{Y}_{j}^A}{S_{j}}.
\end{align*}

with the effect size in the numerator and the pooled standard deviation in the denominator. In a small sample size setting the estimated standard deviations exhibit high variability which can lead to large Z-scores. Extensive statistical methodology has been developed to counteract this challenge. The key idea of those methods is based to *shrinks* the gene-wise variances $\rm S^2_{j}$ towards a common variance $S^2_0$

\begin{align*}
\tilde{S}_{j}^2&=\frac{d_0 S_0^2+d S^2_{j}}{d_0+d}.
\end{align*}

A so-called *moderated* Z-score is obtained by replacing the denominator with the "shrunken" $\tilde{S}_{j}$. The *moderated* Z-score has favourable statistical properties in the small $n$ setting. The statistical methodology behind the approach is referred to as empirical Bayes and is implemented in the function `eBayes` of the `limma` package. Limma starts with running gene-wise linear regression using the `lmFit` function.

```{r}
library(limma)
# first argument: gene expression matrix with genes in rows and sample in columns
# second argument: design matrix
fit <- lmFit(t(y), design=model.matrix(~ x)) 
head(coef(fit))
```

We can compare it with a stanard `lm` fit.
```{r}
coef(lm(y[,1]~x)) # gene 1
coef(lm(y[,2]~x)) # gene 2
```

Next, we use the `eBayes` function to calculate the moderated t statistics and p-values. 

```{r}
ebfit <- eBayes(fit)
head(ebfit$t) # moderated t statistics
head(ebfit$p.value) # p.values based on moderated t statistics
```
We can also retrieved the "shrunken" standard deviations.

```{r}
head(ebfit$s2.post) # shrunken standard deviations
```



<!-- ```{r include=FALSE} -->
<!-- library(tidyverse) -->
<!-- library(devtools) -->
<!-- install_github("genomicsclass/GSE5859Subset") -->
<!-- library("GSE5859Subset") -->
<!-- ``` -->

<!-- We have RNA expression measurements for 8793 genes from blood taken from 24 individuals (the experimental units). For most statistical analyses, we will also need information about the individuals. For example, in this case the data was originally collected to compare gene expression across ethnic groups. However, we have created a subset of this dataset for illustration and separated the data into two groups: -->

<!-- ```{r} -->
<!-- library(GSE5859Subset) -->
<!-- data(GSE5859Subset) ##this loads the three tables -->
<!-- dim(geneExpression) -->

<!-- head(sampleInfo) -->

<!-- head(geneAnnotation) -->
<!-- g <- factor(sampleInfo$group) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- t.d <- data.frame(y=geneExpression[25,],x=g) -->
<!-- t.d%>% -->
<!--   ggplot(.,aes(x=x,y=y))+ -->
<!--   geom_boxplot()+ -->
<!--   geom_jitter(width=0.25)+ -->
<!--   theme_bw()+ -->
<!--   ylab("Gene25")+ -->
<!--   xlab("") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- myttest <- function(x) t.test(x[g==1],x[g==0],var.equal=TRUE)$p.value -->
<!-- pvals <- apply(geneExpression,1,myttest) -->
<!-- ``` -->



<!-- ```{r} -->
<!-- library(Biobase) -->
<!-- library(maPooling) -->
<!-- data(maPooling) ##this loads the three tables -->
<!-- pd <- pData(maPooling) -->
<!-- individuals <- which(rowSums(pd)==1) -->
<!-- geneexpr <- exprs(maPooling)[,individuals] -->
<!-- g <- factor(as.numeric(grepl("b",names(individuals)))) -->
<!-- levels(g) <- c("Stamm 1","Stamm 2") -->

<!-- boxplot(geneexpr[11425,]~g) -->
<!-- t.test(geneexpr[11425,]~x,var.equal=TRUE)$p.value -->
<!-- ``` -->


<!-- ```{r} -->
<!-- boxplot(geneexpr[11878,]~g) -->
<!-- t.test(geneexpr[11878,]~g,var.equal=TRUE)$p.value -->
<!-- ``` -->

