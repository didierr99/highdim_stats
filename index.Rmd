--- 
title: "High-dimensional statistics"
author: "Nicolas St√§dler"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: github.roche.com/staedlen/highdim_stats
description: "This book is for the CAS Module High-dimensional statistics"
---

# Prerequisites

This book is thought as accompanying material for the course on *High-dimensional statistics*.
The content is heavily based on other work [@elements].

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warnings=FALSE)
```

```{r include=FALSE}
library(knitr)
library(tidyverse)
```

## General Notation
We will typically denote an input variable by the symbol $X$. If $X$ is a vector, its components can be accessed
by subscripts $X_j$. Quantative outputs will be denoted by $Y$, and qualitative outputs by $G$ (for group). We use uppercase letters such as $X$, $Y$ or $G$ when referring to the generic aspects of a variable. Observed values are written in lowercase; hence $i$th observed value of $X$ is written as $x_i$ (where $x_i$ is again a scalar or vector). Matrices are represented by bold uppercase letters; for example, a set of $N$ input p-vectors $x_i$, $i=1,\ldots,N$ would be represented by the $N\times p$ matrix $\bf{X}$. All vectors are assumed to be column vectors, the $i$th row of $\bf{X}$ is $x_i^T$.

For the moment we can loosely state the learning task as follows: given the value of an input vector $X$, make a good prediction of the output $Y$, denoted by $\hat Y$ (pronounced "y-hat"). $\hat Y$ is the outcome of a learning rule $\hat{f}(X)$.

We need data to construct learning rules. We thus suppose we have available a set of measurements $(x_i,y_i)$, $i=1,\ldots,N$, known as the training data, with which to construct $\hat{f}(X)$. 

## Statistical Learning

A key goal of a statistical learning is prediction. Therefore the assessment of how the method generalizes beyond 
the observed data is extremely important in practice. 

When building a good learning rule $\hat{f}(X)$ we need to keep in mind the following 2 fundamental steps:

1. Training step: In this step we explore based on training data a series of learning rules $\hat{f}_{\alpha}(X)$, where the index $\alpha$ is a tuning parameter. We compare the prediction performance of each rule and choose the model with smallest least error.
This step is often referred to as model selection. Approximate of the prediction error is either achieved analytically using so-call information criteria (e.g. AIC, BIC or Mallows' Cp) or by efficient use of re-sampling (cross-validation and the bootstrap).

2. Testing step: In this step we evaluate the generalization error of the learning rule $\hat{f}(X)$ obtained in step 1 based on independent test data. 

